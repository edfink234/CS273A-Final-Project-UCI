{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fe7b08",
   "metadata": {},
   "source": [
    "# NN Fingerprint Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c138fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (129012, 2048)\n",
      "y shape: (129012,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"qm9_fp_U0.csv\")\n",
    "\n",
    "# Columns:\n",
    "# 0 = U0 (target)\n",
    "# 1 = SMILES\n",
    "# 2+ = Fingerprints\n",
    "\n",
    "# Target\n",
    "y = df.iloc[:, 0].values.astype(float)\n",
    "\n",
    "# Drop SMILES (col 1)\n",
    "X = df.iloc[:, 2:].values.astype(float)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "320d9cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (103209, 2048)\n",
      "Val: (12901, 2048)\n",
      "Test: (12902, 2048)\n"
     ]
    }
   ],
   "source": [
    "# First: 80% / 20%\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Split the 20% temp into 10% val + 10% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.50,   # half of 20% â†’ 10%\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:\", X_val.shape)\n",
    "print(\"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298af6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "y_train mean/std: -11178.274191566177 1087.6680575550738\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colli\\AppData\\Local\\Temp\\ipykernel_56612\\2527933352.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> val RMSE 0.4040 | 0.65 min | best ep 33\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4131 | 0.45 min | best ep 22\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4121 | 0.58 min | best ep 29\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4190 | 0.77 min | best ep 45\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3999 | 0.60 min | best ep 30\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4125 | 0.55 min | best ep 28\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4020 | 1.09 min | best ep 59\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4223 | 0.58 min | best ep 30\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3911 | 1.07 min | best ep 57\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4048 | 0.84 min | best ep 47\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3964 | 1.12 min | best ep 63\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3994 | 1.44 min | best ep 89\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3903 | 0.99 min | best ep 52\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4006 | 1.16 min | best ep 69\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4037 | 1.28 min | best ep 71\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4082 | 1.05 min | best ep 62\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3970 | 0.47 min | best ep 20\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4066 | 0.59 min | best ep 31\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3949 | 1.00 min | best ep 54\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4059 | 0.78 min | best ep 44\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3950 | 0.53 min | best ep 24\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4037 | 0.45 min | best ep 21\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3926 | 0.78 min | best ep 40\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4077 | 0.65 min | best ep 35\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3930 | 1.12 min | best ep 61\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3996 | 0.84 min | best ep 48\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3940 | 0.98 min | best ep 52\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3989 | 1.02 min | best ep 60\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3942 | 0.59 min | best ep 27\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3939 | 0.98 min | best ep 57\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3937 | 1.07 min | best ep 58\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4003 | 1.27 min | best ep 78\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3873 | 0.67 min | best ep 31\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3964 | 0.65 min | best ep 34\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3895 | 1.07 min | best ep 56\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4090 | 0.87 min | best ep 49\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3841 | 0.84 min | best ep 42\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3933 | 0.68 min | best ep 37\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3943 | 0.73 min | best ep 36\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4072 | 0.68 min | best ep 37\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3906 | 0.69 min | best ep 32\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3975 | 0.65 min | best ep 34\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3942 | 0.88 min | best ep 44\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4046 | 0.68 min | best ep 36\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3919 | 0.84 min | best ep 42\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3979 | 0.64 min | best ep 34\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3937 | 0.74 min | best ep 36\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.4082 | 0.54 min | best ep 27\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3847 | 0.68 min | best ep 32\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3935 | 0.47 min | best ep 22\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3849 | 0.60 min | best ep 27\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3910 | 0.57 min | best ep 29\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3828 | 0.98 min | best ep 51\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3943 | 0.62 min | best ep 33\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3844 | 0.75 min | best ep 37\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3913 | 0.58 min | best ep 30\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3924 | 0.56 min | best ep 24\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3865 | 0.81 min | best ep 45\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3806 | 0.92 min | best ep 46\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3894 | 0.94 min | best ep 54\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3890 | 0.56 min | best ep 24\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3852 | 0.69 min | best ep 37\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3801 | 1.14 min | best ep 60\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 2048, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE 0.3829 | 1.18 min | best ep 71\n",
      "\n",
      "Best config: {'hidden': '[1024, 512, 256]', 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10, 'rmse_val': 0.3800932784161868, 'secs': 68.29583550000098, 'best_epoch': 60}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colli\\AppData\\Local\\Temp\\ipykernel_56612\\2527933352.py:153: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  crit = nn.MSELoss(); scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NN Test ===\n",
      "RMSE 412.080231 | MAE 230.225250 | R^2 0.857525\n"
     ]
    }
   ],
   "source": [
    "import os, time, json, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---- scale X on train only; scale y too ----\n",
    "x_scaler = StandardScaler().fit(X_train.astype(np.float32))\n",
    "Xtr = x_scaler.transform(X_train.astype(np.float32))\n",
    "Xva = x_scaler.transform(X_val.astype(np.float32))\n",
    "Xte = x_scaler.transform(X_test.astype(np.float32))\n",
    "\n",
    "y_scaler = StandardScaler().fit(y_train.reshape(-1,1).astype(np.float32))\n",
    "ytr = y_scaler.transform(y_train.reshape(-1,1).astype(np.float32)).astype(np.float32)\n",
    "yva = y_scaler.transform(y_val.reshape(-1,1).astype(np.float32)).astype(np.float32)\n",
    "yte = y_scaler.transform(y_test.reshape(-1,1).astype(np.float32)).astype(np.float32)\n",
    "\n",
    "print(\"y_train mean/std:\", y_train.mean(), y_train.std())\n",
    "\n",
    "# ---- model ----\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_in, hidden, act=\"relu\", p=0.0):\n",
    "        super().__init__()\n",
    "        A = nn.ReLU if act==\"relu\" else nn.GELU\n",
    "        layers=[]; prev=d_in\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(prev,h), A(), nn.Dropout(p)]\n",
    "            prev=h\n",
    "        layers += [nn.Linear(prev,1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "def loaders(Xtr, ytr, Xva, yva, bs):\n",
    "    ds_tr = TensorDataset(torch.from_numpy(Xtr), torch.from_numpy(ytr))\n",
    "    ds_va = TensorDataset(torch.from_numpy(Xva), torch.from_numpy(yva))\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=bs, shuffle=True, pin_memory=True)\n",
    "    dl_va = DataLoader(ds_va, batch_size=max(bs, 2048), shuffle=False, pin_memory=True)\n",
    "    return dl_tr, dl_va\n",
    "\n",
    "def train_cfg(cfg):\n",
    "    hidden   = cfg[\"hidden\"]\n",
    "    act      = cfg[\"act\"]\n",
    "    p        = cfg[\"dropout\"]\n",
    "    wd       = cfg[\"weight_decay\"]\n",
    "    lr       = cfg[\"lr\"]\n",
    "    bs       = cfg[\"batch_size\"]\n",
    "    max_ep   = cfg[\"epochs\"]\n",
    "    patience = cfg[\"patience\"]\n",
    "\n",
    "    dl_tr, dl_va = loaders(Xtr, ytr, Xva, yva, bs)\n",
    "    model = FFN(Xtr.shape[1], hidden, act, p).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
    "    crit = nn.MSELoss()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n",
    "\n",
    "    best = {\"rmse_val\": float(\"inf\"), \"state\": None, \"epoch\": -1}\n",
    "    wait = 0; t0 = time.perf_counter()\n",
    "\n",
    "    for ep in range(1, max_ep+1):\n",
    "        model.train(); tr_loss=0.0; nb=0\n",
    "        for xb,yb in dl_tr:\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "                pred = model(xb); loss = crit(pred,yb)\n",
    "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "            tr_loss += loss.item(); nb += 1\n",
    "\n",
    "        # val\n",
    "        model.eval(); mse=0.0; n=0\n",
    "        with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            for xb,yb in dl_va:\n",
    "                xb,yb = xb.to(device), yb.to(device)\n",
    "                pred = model(xb)\n",
    "                mse += ((pred-yb)**2).mean().item(); n+=1\n",
    "        mse /= max(1,n); rmse_val = float(np.sqrt(mse))\n",
    "        sched.step(mse)\n",
    "\n",
    "        if rmse_val < best[\"rmse_val\"] - 1e-6:\n",
    "            best.update({\"rmse_val\": rmse_val, \"state\": model.state_dict(), \"epoch\": ep})\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience: break\n",
    "\n",
    "    secs = time.perf_counter() - t0\n",
    "    return best[\"rmse_val\"], best[\"state\"], secs, best[\"epoch\"]\n",
    "\n",
    "# ---- grid ----\n",
    "grid = {\n",
    "    \"hidden\":      [[512,256], [1024,512,256]],\n",
    "    \"act\":         [\"relu\", \"gelu\"],\n",
    "    \"dropout\":     [0.0, 0.1],\n",
    "    \"weight_decay\":[1e-5, 1e-4],\n",
    "    \"lr\":          [1e-3, 5e-4],\n",
    "    \"batch_size\":  [1024, 2048],\n",
    "    \"epochs\":      [100],\n",
    "    \"patience\":    [10],\n",
    "}\n",
    "\n",
    "def configs(g):\n",
    "    keys = list(g.keys())\n",
    "    for vals in product(*[g[k] for k in keys]):\n",
    "        yield dict(zip(keys, vals))\n",
    "\n",
    "# ---- streaming search (resumable) ----\n",
    "out = Path(\"artifacts_nn\"); out.mkdir(exist_ok=True)\n",
    "csv = out / \"nn_val_search_stream.csv\"\n",
    "done = set()\n",
    "if csv.exists():\n",
    "    prev = pd.read_csv(csv)\n",
    "    for _,r in prev.iterrows():\n",
    "        d = {k: r[k] for k in [\"hidden\",\"act\",\"dropout\",\"weight_decay\",\"lr\",\"batch_size\",\"epochs\",\"patience\"]}\n",
    "        done.add(json.dumps(d, sort_keys=True))\n",
    "\n",
    "for cfg in configs(grid):\n",
    "    key = json.dumps(cfg, sort_keys=True)\n",
    "    if key in done:\n",
    "        print(\"Skip:\", cfg); continue\n",
    "    print(\"Train:\", cfg)\n",
    "    rmse_val, state, secs, best_ep = train_cfg(cfg)\n",
    "    row = dict(cfg); row.update({\"rmse_val\": rmse_val, \"secs\": secs, \"best_epoch\": best_ep})\n",
    "    pd.DataFrame([row]).to_csv(csv, mode=\"a\", header=not csv.exists(), index=False)\n",
    "    print(f\"-> val RMSE {rmse_val:.4f} | {secs/60:.2f} min | best ep {best_ep}\")\n",
    "\n",
    "# ---- pick best, retrain on train+val, test (inverse-transform reporting) ----\n",
    "all_df = pd.read_csv(csv).sort_values(\"rmse_val\").reset_index(drop=True)\n",
    "best = all_df.iloc[0].to_dict()\n",
    "print(\"\\nBest config:\", best)\n",
    "\n",
    "# retrain best on train+val\n",
    "Xtv = np.vstack([Xtr, Xva]); ytv = np.vstack([ytr, yva])\n",
    "bs = int(best[\"batch_size\"])\n",
    "dl_tv = DataLoader(TensorDataset(torch.from_numpy(Xtv), torch.from_numpy(ytv)),\n",
    "                   batch_size=bs, shuffle=True, pin_memory=True)\n",
    "dl_te = DataLoader(TensorDataset(torch.from_numpy(Xte), torch.from_numpy(yte)),\n",
    "                   batch_size=max(bs,2048), shuffle=False, pin_memory=True)\n",
    "\n",
    "model = FFN(\n",
    "    Xtr.shape[1],\n",
    "    hidden=eval(best[\"hidden\"]) if isinstance(best[\"hidden\"], str) else best[\"hidden\"],\n",
    "    act=best[\"act\"],\n",
    "    p=float(best[\"dropout\"])\n",
    ").to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=float(best[\"lr\"]), weight_decay=float(best[\"weight_decay\"]))\n",
    "crit = nn.MSELoss(); scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n",
    "\n",
    "E = int(best[\"best_epoch\"]) + 5\n",
    "for ep in range(E):\n",
    "    model.train()\n",
    "    for xb,yb in dl_tv:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            pred = model(xb); loss = crit(pred,yb)\n",
    "        scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "\n",
    "# test (inverse-transform to original units)\n",
    "model.eval(); preds=[]\n",
    "with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "    for xb,yb in dl_te:\n",
    "        xb = xb.to(device)\n",
    "        preds.append(model(xb).cpu().numpy())\n",
    "y_pred_scaled = np.vstack(preds).ravel()\n",
    "\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()\n",
    "y_true = y_scaler.inverse_transform(yte).ravel()\n",
    "rmse_test = np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "mae_test  = np.mean(np.abs(y_pred - y_true))\n",
    "ss_res = np.sum((y_pred - y_true)**2)\n",
    "ss_tot = np.sum((y_true - y_true.mean())**2)\n",
    "r2_test  = 1 - ss_res/ss_tot\n",
    "\n",
    "print(f\"\\n=== NN Test ===\\nRMSE {rmse_test:.6f} | MAE {mae_test:.6f} | R^2 {r2_test:.6f}\")\n",
    "\n",
    "import joblib\n",
    "joblib.dump({\"x_scaler\": x_scaler, \"y_scaler\": y_scaler,\n",
    "             \"state_dict\": model.state_dict(), \"config\": best},\n",
    "            out / \"nn_best_model.joblib\")\n",
    "pd.DataFrame({\"y_true\": y_true, \"y_pred\": y_pred}).to_csv(out / \"test_preds.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b00e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colli\\AppData\\Local\\Temp\\ipykernel_56612\\170025695.py:66: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 34 | val RMSE (scaled): 0.3808 | time: 0.77 min\n",
      "\n",
      "=== Metrics (original units) ===\n",
      "Train: RMSE 45.88 | MAE 24.56 | R^2 0.9982\n",
      "Val  : RMSE 417.30 | MAE 251.40 | R^2 0.8516\n",
      "Test : RMSE 419.74 | MAE 254.55 | R^2 0.8522\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, torch, torch.nn as nn, time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ==== 0) Load your splits ====\n",
    "# If you already have X_train, y_train, X_val, y_val, X_test, y_test in memory, skip this section.\n",
    "# Otherwise, uncomment and point to your files (CSV/NPY). Assumes features in X_* and targets in y_*.\n",
    "X_train = np.load(\"X_train.npy\"); y_train = np.load(\"y_train.npy\")\n",
    "X_val   = np.load(\"X_val.npy\");   y_val   = np.load(\"y_val.npy\")\n",
    "X_test  = np.load(\"X_test.npy\");  y_test  = np.load(\"y_test.npy\")\n",
    "\n",
    "assert all(v in globals() for v in [\"X_train\",\"y_train\",\"X_val\",\"y_val\",\"X_test\",\"y_test\"]), \"Define your splits first.\"\n",
    "\n",
    "# ==== 1) Scale X on train only; scale y on train only ====\n",
    "x_scaler = StandardScaler().fit(X_train.astype(np.float32))\n",
    "Xtr = x_scaler.transform(X_train.astype(np.float32))\n",
    "Xva = x_scaler.transform(X_val.astype(np.float32))\n",
    "Xte = x_scaler.transform(X_test.astype(np.float32))\n",
    "\n",
    "y_scaler = StandardScaler().fit(y_train.reshape(-1,1).astype(np.float32))\n",
    "ytr = y_scaler.transform(y_train.reshape(-1,1).astype(np.float32)).astype(np.float32)\n",
    "yva = y_scaler.transform(y_val.reshape(-1,1).astype(np.float32)).astype(np.float32)\n",
    "yte = y_scaler.transform(y_test.reshape(-1,1).astype(np.float32)).astype(np.float32)\n",
    "\n",
    "# ==== 2) Dataloaders ====\n",
    "def make_loader(X, y, bs, shuffle):\n",
    "    ds = TensorDataset(torch.from_numpy(X), torch.from_numpy(y))\n",
    "    return DataLoader(ds, batch_size=bs, shuffle=shuffle, pin_memory=True)\n",
    "\n",
    "BS = 1024\n",
    "dl_tr = make_loader(Xtr, ytr, BS, True)\n",
    "dl_va = make_loader(Xva, yva, max(BS, 2048), False)\n",
    "dl_te = make_loader(Xte, yte, max(BS, 2048), False)\n",
    "\n",
    "# ==== 3) Model ====\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_in, hidden=(1024,512,256), p=0.1, act=\"gelu\"):\n",
    "        super().__init__()\n",
    "        A = nn.GELU if act==\"gelu\" else nn.ReLU\n",
    "        layers=[]; prev=d_in\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(prev,h), A(), nn.Dropout(p)]\n",
    "            prev=h\n",
    "        layers += [nn.Linear(prev,1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "model = FFN(Xtr.shape[1], hidden=(1024,512,256), p=0.1, act=\"gelu\").to(device)\n",
    "\n",
    "# ==== 4) Train w/ early stopping ====\n",
    "LR = 5e-4\n",
    "WD = 1e-4\n",
    "EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
    "\n",
    "crit = nn.MSELoss()\n",
    "scaler_amp = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n",
    "\n",
    "best = {\"rmse_val\": float(\"inf\"), \"state\": None, \"epoch\": -1}\n",
    "wait = 0\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "def eval_rmse_scaled(m, loader):\n",
    "    m.eval()\n",
    "    mse = 0.0; n = 0\n",
    "    with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "        for xb,yb in loader:\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            pred = m(xb)\n",
    "            mse += ((pred-yb)**2).mean().item(); n += 1\n",
    "    return float(np.sqrt(mse / max(1,n)))\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train(); nb=0; tr_mse=0.0\n",
    "    for xb,yb in dl_tr:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            pred = model(xb); loss = crit(pred,yb)\n",
    "        scaler_amp.scale(loss).backward(); scaler_amp.step(opt); scaler_amp.update()\n",
    "        tr_mse += loss.item(); nb += 1\n",
    "\n",
    "    rmse_val_scaled = eval_rmse_scaled(model, dl_va)\n",
    "    sched.step(rmse_val_scaled**2)\n",
    "\n",
    "    if rmse_val_scaled < best[\"rmse_val\"] - 1e-6:\n",
    "        best.update({\"rmse_val\": rmse_val_scaled, \"state\": model.state_dict(), \"epoch\": ep})\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= PATIENCE: break\n",
    "\n",
    "elapsed = time.perf_counter() - t0\n",
    "print(f\"Best epoch: {best['epoch']} | val RMSE (scaled): {best['rmse_val']:.4f} | time: {elapsed/60:.2f} min\")\n",
    "\n",
    "# Restore best\n",
    "model.load_state_dict(best[\"state\"])\n",
    "\n",
    "# ==== 5) Evaluate on Train / Val / Test in ORIGINAL UNITS ====\n",
    "def evaluate_original_units(m, X, y_scaled, y_true):\n",
    "    m.eval(); preds=[]\n",
    "    loader = DataLoader(TensorDataset(torch.from_numpy(X), torch.from_numpy(y_scaled)),\n",
    "                        batch_size=max(BS,2048), shuffle=False, pin_memory=True)\n",
    "    with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "        for xb,_ in loader:\n",
    "            xb = xb.to(device)\n",
    "            preds.append(m(xb).cpu().numpy())\n",
    "    y_pred_scaled = np.vstack(preds).ravel()\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    r2   = float(r2_score(y_true, y_pred))\n",
    "    return rmse, mae, r2\n",
    "\n",
    "rmse_tr, mae_tr, r2_tr = evaluate_original_units(model, Xtr, ytr, y_train.ravel())\n",
    "rmse_va, mae_va, r2_va = evaluate_original_units(model, Xva, yva, y_val.ravel())\n",
    "rmse_te, mae_te, r2_te = evaluate_original_units(model, Xte, yte, y_test.ravel())\n",
    "\n",
    "print(\"\\n=== Metrics (original units) ===\")\n",
    "print(f\"Train: RMSE {rmse_tr:.2f} | MAE {mae_tr:.2f} | R^2 {r2_tr:.4f}\")\n",
    "print(f\"Val  : RMSE {rmse_va:.2f} | MAE {mae_va:.2f} | R^2 {r2_va:.4f}\")\n",
    "print(f\"Test : RMSE {rmse_te:.2f} | MAE {mae_te:.2f} | R^2 {r2_te:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d7c6a",
   "metadata": {},
   "source": [
    "# NN Descriptor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ca3e62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Descriptor matrix shape: (129012, 194)\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0055 | 1.56 min | best ep 98\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0073 | 1.25 min | best ep 100\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0071 | 1.63 min | best ep 99\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0092 | 1.35 min | best ep 97\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0059 | 1.64 min | best ep 95\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0071 | 1.39 min | best ep 100\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0063 | 1.60 min | best ep 100\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0088 | 1.33 min | best ep 98\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0101 | 1.12 min | best ep 58\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0094 | 1.02 min | best ep 73\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0095 | 0.96 min | best ep 50\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0129 | 0.89 min | best ep 56\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0086 | 1.42 min | best ep 78\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0089 | 1.30 min | best ep 91\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0100 | 1.02 min | best ep 56\n",
      "Train: {'hidden': [512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0108 | 0.83 min | best ep 58\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0048 | 1.51 min | best ep 98\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0056 | 1.24 min | best ep 99\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0048 | 1.54 min | best ep 97\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0061 | 1.34 min | best ep 100\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0047 | 1.62 min | best ep 100\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0055 | 1.34 min | best ep 97\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0050 | 1.60 min | best ep 100\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0053 | 1.35 min | best ep 100\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0078 | 1.33 min | best ep 74\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0082 | 1.11 min | best ep 73\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0083 | 1.17 min | best ep 59\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0091 | 0.94 min | best ep 58\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0067 | 1.68 min | best ep 95\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0078 | 1.19 min | best ep 79\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0087 | 1.13 min | best ep 57\n",
      "Train: {'hidden': [512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0091 | 1.23 min | best ep 78\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0059 | 1.80 min | best ep 100\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0071 | 1.42 min | best ep 100\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0061 | 1.70 min | best ep 97\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0077 | 1.29 min | best ep 96\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0059 | 1.64 min | best ep 100\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0072 | 1.39 min | best ep 99\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0066 | 1.72 min | best ep 99\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0081 | 1.36 min | best ep 100\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0162 | 0.62 min | best ep 26\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0159 | 0.41 min | best ep 19\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0193 | 0.65 min | best ep 27\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0213 | 0.29 min | best ep 11\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0176 | 0.34 min | best ep 10\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0186 | 0.34 min | best ep 14\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0181 | 0.44 min | best ep 16\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'relu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0179 | 0.33 min | best ep 13\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0046 | 1.70 min | best ep 97\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0051 | 1.39 min | best ep 97\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0050 | 1.68 min | best ep 96\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0057 | 1.32 min | best ep 100\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0045 | 1.62 min | best ep 99\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0053 | 1.31 min | best ep 100\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0056 | 1.63 min | best ep 99\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0054 | 1.32 min | best ep 97\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0117 | 1.39 min | best ep 76\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0101 | 0.83 min | best ep 56\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0085 | 1.48 min | best ep 80\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 1e-05, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0105 | 0.79 min | best ep 53\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0115 | 0.98 min | best ep 50\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0100 | 1.05 min | best ep 73\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 512, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0099 | 0.99 min | best ep 49\n",
      "Train: {'hidden': [1024, 512, 256], 'act': 'gelu', 'dropout': 0.1, 'weight_decay': 0.0001, 'lr': 0.0005, 'batch_size': 1024, 'epochs': 100, 'patience': 10}\n",
      "-> val RMSE (scaled) 0.0108 | 1.08 min | best ep 67\n",
      "\n",
      "Best (descriptors): {'hidden': '[1024, 512, 256]', 'act': 'gelu', 'dropout': 0.0, 'weight_decay': 0.0001, 'lr': 0.001, 'batch_size': 512, 'epochs': 100, 'patience': 10, 'rmse_val': 0.0044754572966016, 'secs': 97.057158599986, 'best_epoch': 99}\n",
      "\n",
      "=== Descriptors NN Test ===\n",
      "RMSE 8.951091 | MAE 5.515498 | R^2 0.999933\n",
      "\n",
      "=== Comparison (lower is better) ===\n",
      "            model       RMSE        MAE       R2\n",
      "NN (descriptors)    8.951091   5.515498 0.999933\n",
      "NN (fingerprints) 412.071775 230.224122 0.857530\n"
     ]
    }
   ],
   "source": [
    "# nn_grid_search_descriptors.py\n",
    "import os, json, time, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ========= CONFIG =========\n",
    "SEED = 42\n",
    "np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Path to descriptor CSV (col0=U0, col1=SMILES, rest=descriptors)\n",
    "DESCRIPTOR_CSV = \"qm9_desc_U0.csv\"   # <--- change if needed\n",
    "\n",
    "# Output folder\n",
    "OUT = Path(\"artifacts_nn_desc\"); OUT.mkdir(exist_ok=True)\n",
    "CSV_RESULTS = OUT / \"nn_val_search_stream_desc.csv\"\n",
    "\n",
    "# Small grid (tight, effective)\n",
    "GRID = {\n",
    "    \"hidden\":      [[512,256], [1024,512,256]],\n",
    "    \"act\":         [\"relu\", \"gelu\"],\n",
    "    \"dropout\":     [0.0, 0.1],\n",
    "    \"weight_decay\":[1e-5, 1e-4],\n",
    "    \"lr\":          [1e-3, 5e-4],\n",
    "    \"batch_size\":  [512, 1024],\n",
    "    \"epochs\":      [100],\n",
    "    \"patience\":    [10],\n",
    "}\n",
    "# ==========================\n",
    "\n",
    "# ========= LOAD DATA =========\n",
    "df = pd.read_csv(DESCRIPTOR_CSV)\n",
    "y_all = df.iloc[:,0].to_numpy(np.float32)\n",
    "X_all = df.iloc[:,2:].to_numpy(np.float32)  # skip U0 and SMILES\n",
    "print(\"Descriptor matrix shape:\", X_all.shape)\n",
    "\n",
    "# Same 80/10/10 split pattern (deterministic)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=SEED, shuffle=True\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=SEED, shuffle=True\n",
    ")\n",
    "\n",
    "# Scale X on train only; scale y for training stability\n",
    "x_scaler = StandardScaler().fit(X_train)\n",
    "Xtr = x_scaler.transform(X_train).astype(np.float32)\n",
    "Xva = x_scaler.transform(X_val).astype(np.float32)\n",
    "Xte = x_scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "y_scaler = StandardScaler().fit(y_train.reshape(-1,1))\n",
    "ytr = y_scaler.transform(y_train.reshape(-1,1)).astype(np.float32)\n",
    "yva = y_scaler.transform(y_val.reshape(-1,1)).astype(np.float32)\n",
    "yte = y_scaler.transform(y_test.reshape(-1,1)).astype(np.float32)\n",
    "\n",
    "# ========= MODEL / TRAINING =========\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_in, hidden, act=\"relu\", p=0.0):\n",
    "        super().__init__()\n",
    "        A = nn.ReLU if act==\"relu\" else nn.GELU\n",
    "        layers=[]; prev=d_in\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(prev,h), A(), nn.Dropout(p)]\n",
    "            prev=h\n",
    "        layers += [nn.Linear(prev,1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "def make_loaders(Xtr, ytr, Xva, yva, bs):\n",
    "    ds_tr = TensorDataset(torch.from_numpy(Xtr), torch.from_numpy(ytr))\n",
    "    ds_va = TensorDataset(torch.from_numpy(Xva), torch.from_numpy(yva))\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=bs, shuffle=True,  pin_memory=True)\n",
    "    dl_va = DataLoader(ds_va, batch_size=max(bs,2048), shuffle=False, pin_memory=True)\n",
    "    return dl_tr, dl_va\n",
    "\n",
    "def train_one(cfg):\n",
    "    hidden   = cfg[\"hidden\"]\n",
    "    act      = cfg[\"act\"]\n",
    "    p        = cfg[\"dropout\"]\n",
    "    wd       = cfg[\"weight_decay\"]\n",
    "    lr       = cfg[\"lr\"]\n",
    "    bs       = cfg[\"batch_size\"]\n",
    "    max_ep   = cfg[\"epochs\"]\n",
    "    patience = cfg[\"patience\"]\n",
    "\n",
    "    dl_tr, dl_va = make_loaders(Xtr, ytr, Xva, yva, bs)\n",
    "    model = FFN(Xtr.shape[1], hidden, act, p).to(device)\n",
    "    opt   = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
    "    crit  = nn.MSELoss()\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type==\"cuda\"))\n",
    "\n",
    "    best = {\"rmse_val\": float(\"inf\"), \"state\": None, \"epoch\": -1}\n",
    "    wait = 0\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    for ep in range(1, max_ep+1):\n",
    "        model.train(); tr_loss=0.0; nb=0\n",
    "        for xb,yb in dl_tr:\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "                pred = model(xb); loss = crit(pred,yb)\n",
    "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "            tr_loss += loss.item(); nb += 1\n",
    "\n",
    "        model.eval(); mse=0.0; n=0\n",
    "        with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            for xb,yb in dl_va:\n",
    "                xb,yb = xb.to(device), yb.to(device)\n",
    "                pred = model(xb)\n",
    "                mse += ((pred-yb)**2).mean().item(); n += 1\n",
    "        mse /= max(1,n); rmse_val = float(np.sqrt(mse))\n",
    "        sched.step(mse)\n",
    "\n",
    "        if rmse_val < best[\"rmse_val\"] - 1e-6:\n",
    "            best.update({\"rmse_val\": rmse_val, \"state\": {k:v.detach().cpu() for k,v in model.state_dict().items()}, \"epoch\": ep})\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience: break\n",
    "\n",
    "    secs = time.perf_counter() - t0\n",
    "    return best[\"rmse_val\"], best[\"state\"], secs, best[\"epoch\"]\n",
    "\n",
    "def cfg_iter(grid):\n",
    "    keys = list(grid.keys())\n",
    "    for vals in product(*[grid[k] for k in keys]):\n",
    "        yield dict(zip(keys, vals))\n",
    "\n",
    "# ========= STREAMING GRID SEARCH =========\n",
    "done = set()\n",
    "if CSV_RESULTS.exists():\n",
    "    prev = pd.read_csv(CSV_RESULTS)\n",
    "    for _,r in prev.iterrows():\n",
    "        d = {k: r[k] for k in [\"hidden\",\"act\",\"dropout\",\"weight_decay\",\"lr\",\"batch_size\",\"epochs\",\"patience\"]}\n",
    "        done.add(json.dumps(d, sort_keys=True))\n",
    "\n",
    "for cfg in cfg_iter(GRID):\n",
    "    key = json.dumps(cfg, sort_keys=True)\n",
    "    if key in done:\n",
    "        print(\"Skip:\", cfg); continue\n",
    "    print(\"Train:\", cfg)\n",
    "    rmse_val, state, secs, best_ep = train_one(cfg)\n",
    "    row = dict(cfg); row.update({\"rmse_val\": rmse_val, \"secs\": secs, \"best_epoch\": best_ep})\n",
    "    pd.DataFrame([row]).to_csv(CSV_RESULTS, mode=\"a\", header=not CSV_RESULTS.exists(), index=False)\n",
    "    print(f\"-> val RMSE (scaled) {rmse_val:.4f} | {secs/60:.2f} min | best ep {best_ep}\")\n",
    "\n",
    "# ========= PICK BEST, RETRAIN ON TRAIN+VAL, TEST =========\n",
    "all_df = pd.read_csv(CSV_RESULTS).sort_values(\"rmse_val\").reset_index(drop=True)\n",
    "best = all_df.iloc[0].to_dict()\n",
    "print(\"\\nBest (descriptors):\", best)\n",
    "\n",
    "# Retrain on train+val combined\n",
    "Xtv = np.vstack([Xtr, Xva]); ytv = np.vstack([ytr, yva])\n",
    "bs = int(best[\"batch_size\"])\n",
    "dl_tv = DataLoader(TensorDataset(torch.from_numpy(Xtv), torch.from_numpy(ytv)),\n",
    "                   batch_size=bs, shuffle=True, pin_memory=True)\n",
    "dl_te = DataLoader(TensorDataset(torch.from_numpy(Xte), torch.from_numpy(yte)),\n",
    "                   batch_size=max(bs,2048), shuffle=False, pin_memory=True)\n",
    "\n",
    "model = FFN(\n",
    "    Xtr.shape[1],\n",
    "    hidden=eval(best[\"hidden\"]) if isinstance(best[\"hidden\"], str) else best[\"hidden\"],\n",
    "    act=best[\"act\"],\n",
    "    p=float(best[\"dropout\"])\n",
    ").to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=float(best[\"lr\"]), weight_decay=float(best[\"weight_decay\"]))\n",
    "crit = nn.MSELoss()\n",
    "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type==\"cuda\"))\n",
    "\n",
    "E = int(best[\"best_epoch\"]) + 5\n",
    "for ep in range(E):\n",
    "    model.train()\n",
    "    for xb,yb in dl_tv:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            pred = model(xb); loss = crit(pred,yb)\n",
    "        scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "\n",
    "# Test in original units\n",
    "model.eval(); preds=[]\n",
    "with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "    for xb,yb in dl_te:\n",
    "        xb = xb.to(device)\n",
    "        preds.append(model(xb).cpu().numpy())\n",
    "y_pred_scaled = np.vstack(preds).ravel()\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()\n",
    "y_true = y_scaler.inverse_transform(yte).ravel()\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    rmse = float(np.sqrt(np.mean((y_pred-y_true)**2)))\n",
    "    mae  = float(np.mean(np.abs(y_pred-y_true)))\n",
    "    ss_res = np.sum((y_pred-y_true)**2); ss_tot = np.sum((y_true-y_true.mean())**2)\n",
    "    r2 = float(1 - ss_res/ss_tot)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "rmse_d, mae_d, r2_d = metrics(y_true, y_pred)\n",
    "print(f\"\\n=== Descriptors NN Test ===\\nRMSE {rmse_d:.6f} | MAE {mae_d:.6f} | R^2 {r2_d:.6f}\")\n",
    "\n",
    "# Save artifacts\n",
    "import joblib\n",
    "joblib.dump({\"x_scaler\": x_scaler, \"y_scaler\": y_scaler, \"state_dict\": model.state_dict(), \"config\": best},\n",
    "            OUT / \"nn_desc_best_model.joblib\")\n",
    "pd.DataFrame({\"y_true\": y_true, \"y_pred\": y_pred}).to_csv(OUT / \"test_preds_desc.csv\", index=False)\n",
    "\n",
    "# ========= OPTIONAL: COMPARE TO FINGERPRINT NN IF AVAILABLE =========\n",
    "fp_preds_path = Path(\"artifacts_nn/test_preds.csv\")\n",
    "if fp_preds_path.exists():\n",
    "    df_fp = pd.read_csv(fp_preds_path)\n",
    "    y_true_fp = df_fp[\"y_true\"].to_numpy()\n",
    "    y_pred_fp = df_fp[\"y_pred\"].to_numpy()\n",
    "    rmse_f, mae_f, r2_f = metrics(y_true_fp, y_pred_fp)\n",
    "\n",
    "    comp = pd.DataFrame([\n",
    "        {\"model\":\"NN (fingerprints)\", \"RMSE\":rmse_f, \"MAE\":mae_f, \"R2\":r2_f},\n",
    "        {\"model\":\"NN (descriptors) \", \"RMSE\":rmse_d, \"MAE\":mae_d, \"R2\":r2_d},\n",
    "    ]).sort_values(\"RMSE\")\n",
    "    print(\"\\n=== Comparison (lower is better) ===\")\n",
    "    print(comp.to_string(index=False))\n",
    "    comp.to_csv(OUT / \"nn_fp_vs_desc_metrics.csv\", index=False)\n",
    "else:\n",
    "    print(\"\\nNo fingerprint predictions found at artifacts_nn/test_preds.csv; \"\n",
    "          \"skipping side-by-side comparison.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2119237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Descriptor matrix shape: (129012, 194)\n",
      "Epoch 001 | val RMSE (scaled): 0.037732\n",
      "Epoch 002 | val RMSE (scaled): 0.040970\n",
      "Epoch 003 | val RMSE (scaled): 0.023502\n",
      "Epoch 004 | val RMSE (scaled): 0.023857\n",
      "Epoch 005 | val RMSE (scaled): 0.038393\n",
      "Epoch 006 | val RMSE (scaled): 0.022954\n",
      "Epoch 007 | val RMSE (scaled): 0.030329\n",
      "Epoch 008 | val RMSE (scaled): 0.188664\n",
      "Epoch 009 | val RMSE (scaled): 0.057578\n",
      "Epoch 010 | val RMSE (scaled): 0.026409\n",
      "Epoch 011 | val RMSE (scaled): 0.018251\n",
      "Epoch 012 | val RMSE (scaled): 0.016680\n",
      "Epoch 013 | val RMSE (scaled): 0.014384\n",
      "Epoch 014 | val RMSE (scaled): 0.013559\n",
      "Epoch 015 | val RMSE (scaled): 0.019765\n",
      "Epoch 016 | val RMSE (scaled): 0.016011\n",
      "Epoch 017 | val RMSE (scaled): 0.014517\n",
      "Epoch 018 | val RMSE (scaled): 0.012629\n",
      "Epoch 019 | val RMSE (scaled): 0.011586\n",
      "Epoch 020 | val RMSE (scaled): 0.015068\n",
      "Epoch 021 | val RMSE (scaled): 0.011334\n",
      "Epoch 022 | val RMSE (scaled): 0.011403\n",
      "Epoch 023 | val RMSE (scaled): 0.011770\n",
      "Epoch 024 | val RMSE (scaled): 0.011896\n",
      "Epoch 025 | val RMSE (scaled): 0.010151\n",
      "Epoch 026 | val RMSE (scaled): 0.009189\n",
      "Epoch 027 | val RMSE (scaled): 0.011244\n",
      "Epoch 028 | val RMSE (scaled): 0.008820\n",
      "Epoch 029 | val RMSE (scaled): 0.009023\n",
      "Epoch 030 | val RMSE (scaled): 0.010104\n",
      "Epoch 031 | val RMSE (scaled): 0.011719\n",
      "Epoch 032 | val RMSE (scaled): 0.011698\n",
      "Epoch 033 | val RMSE (scaled): 0.008178\n",
      "Epoch 034 | val RMSE (scaled): 0.007698\n",
      "Epoch 035 | val RMSE (scaled): 0.007551\n",
      "Epoch 036 | val RMSE (scaled): 0.007431\n",
      "Epoch 037 | val RMSE (scaled): 0.007353\n",
      "Epoch 038 | val RMSE (scaled): 0.007444\n",
      "Epoch 039 | val RMSE (scaled): 0.007189\n",
      "Epoch 040 | val RMSE (scaled): 0.007362\n",
      "Epoch 041 | val RMSE (scaled): 0.007059\n",
      "Epoch 042 | val RMSE (scaled): 0.006941\n",
      "Epoch 043 | val RMSE (scaled): 0.006998\n",
      "Epoch 044 | val RMSE (scaled): 0.008046\n",
      "Epoch 045 | val RMSE (scaled): 0.007003\n",
      "Epoch 046 | val RMSE (scaled): 0.007563\n",
      "Epoch 047 | val RMSE (scaled): 0.007447\n",
      "Epoch 048 | val RMSE (scaled): 0.006324\n",
      "Epoch 049 | val RMSE (scaled): 0.006865\n",
      "Epoch 050 | val RMSE (scaled): 0.006282\n",
      "Epoch 051 | val RMSE (scaled): 0.006174\n",
      "Epoch 052 | val RMSE (scaled): 0.008004\n",
      "Epoch 053 | val RMSE (scaled): 0.006305\n",
      "Epoch 054 | val RMSE (scaled): 0.008344\n",
      "Epoch 055 | val RMSE (scaled): 0.011356\n",
      "Epoch 056 | val RMSE (scaled): 0.005878\n",
      "Epoch 057 | val RMSE (scaled): 0.005985\n",
      "Epoch 058 | val RMSE (scaled): 0.005838\n",
      "Epoch 059 | val RMSE (scaled): 0.005893\n",
      "Epoch 060 | val RMSE (scaled): 0.006004\n",
      "Epoch 061 | val RMSE (scaled): 0.005717\n",
      "Epoch 062 | val RMSE (scaled): 0.005597\n",
      "Epoch 063 | val RMSE (scaled): 0.005726\n",
      "Epoch 064 | val RMSE (scaled): 0.005687\n",
      "Epoch 065 | val RMSE (scaled): 0.005604\n",
      "Epoch 066 | val RMSE (scaled): 0.005731\n",
      "Epoch 067 | val RMSE (scaled): 0.005485\n",
      "Epoch 068 | val RMSE (scaled): 0.005519\n",
      "Epoch 069 | val RMSE (scaled): 0.005478\n",
      "Epoch 070 | val RMSE (scaled): 0.005428\n",
      "Epoch 071 | val RMSE (scaled): 0.005493\n",
      "Epoch 072 | val RMSE (scaled): 0.005575\n",
      "Epoch 073 | val RMSE (scaled): 0.005389\n",
      "Epoch 074 | val RMSE (scaled): 0.005306\n",
      "Epoch 075 | val RMSE (scaled): 0.005447\n",
      "Epoch 076 | val RMSE (scaled): 0.005330\n",
      "Epoch 077 | val RMSE (scaled): 0.005486\n",
      "Epoch 078 | val RMSE (scaled): 0.005395\n",
      "Epoch 079 | val RMSE (scaled): 0.005266\n",
      "Epoch 080 | val RMSE (scaled): 0.005233\n",
      "Epoch 081 | val RMSE (scaled): 0.005250\n",
      "Epoch 082 | val RMSE (scaled): 0.005262\n",
      "Epoch 083 | val RMSE (scaled): 0.005249\n",
      "Epoch 084 | val RMSE (scaled): 0.005214\n",
      "Epoch 085 | val RMSE (scaled): 0.005195\n",
      "Epoch 086 | val RMSE (scaled): 0.005210\n",
      "Epoch 087 | val RMSE (scaled): 0.005215\n",
      "Epoch 088 | val RMSE (scaled): 0.005237\n",
      "Epoch 089 | val RMSE (scaled): 0.005238\n",
      "Epoch 090 | val RMSE (scaled): 0.005147\n",
      "Epoch 091 | val RMSE (scaled): 0.005180\n",
      "Epoch 092 | val RMSE (scaled): 0.005154\n",
      "Epoch 093 | val RMSE (scaled): 0.005154\n",
      "Epoch 094 | val RMSE (scaled): 0.005141\n",
      "Epoch 095 | val RMSE (scaled): 0.005122\n",
      "Epoch 096 | val RMSE (scaled): 0.005149\n",
      "Epoch 097 | val RMSE (scaled): 0.005132\n",
      "Epoch 098 | val RMSE (scaled): 0.005133\n",
      "Epoch 099 | val RMSE (scaled): 0.005141\n",
      "Epoch 100 | val RMSE (scaled): 0.005087\n",
      "Training time: 96.6s\n",
      "\n",
      "=== Final Metrics (Descriptor NN; match-grid) ===\n",
      "Train: RMSE=3.793453 | MAE=2.863194 | R2=0.999988\n",
      "Val:   RMSE=6.063666 | MAE=3.476330 | R2=0.999969\n",
      "Test:  RMSE=5.579133 | MAE=3.452437 | R2=0.999974\n",
      "Saved test predictions â†’ artifacts_nn_desc\\test_preds_desc.csv\n",
      "Saved model â†’ artifacts_nn_desc\\nn_desc_best_matchgrid.pth\n"
     ]
    }
   ],
   "source": [
    "# nn_best_desc_retrain_matchgrid.py\n",
    "import time, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ========= CONFIG =========\n",
    "SEED = 42\n",
    "np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "CSV = \"qm9_desc_U0.csv\"          # col0=U0, col1=SMILES, rest=descriptors\n",
    "OUT = Path(\"artifacts_nn_desc\"); OUT.mkdir(exist_ok=True)\n",
    "PRED_CSV = OUT / \"test_preds_desc.csv\"\n",
    "MODEL_PTH = OUT / \"nn_desc_best_matchgrid.pth\"\n",
    "\n",
    "# Best from your search\n",
    "hidden       = [1024, 512, 256]\n",
    "act_name     = \"gelu\"            # {\"relu\",\"gelu\"}\n",
    "dropout_p    = 0.0\n",
    "weight_decay = 1e-4\n",
    "lr           = 1e-3\n",
    "batch_size   = 512\n",
    "epochs       = 100\n",
    "patience     = 10\n",
    "# ==========================\n",
    "\n",
    "# ========= LOAD / SPLIT / SCALE (identical to grid) =========\n",
    "df = pd.read_csv(CSV)\n",
    "y_all = df.iloc[:,0].to_numpy(np.float32)\n",
    "X_all = df.iloc[:,2:].to_numpy(np.float32)\n",
    "print(\"Descriptor matrix shape:\", X_all.shape)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=SEED, shuffle=True\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=SEED, shuffle=True\n",
    ")\n",
    "\n",
    "x_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train.reshape(-1,1))\n",
    "\n",
    "Xtr = x_scaler.transform(X_train).astype(np.float32)\n",
    "Xva = x_scaler.transform(X_val).astype(np.float32)\n",
    "Xte = x_scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "# NOTE: keep y as (N,1) like the grid code\n",
    "ytr = y_scaler.transform(y_train.reshape(-1,1)).astype(np.float32)\n",
    "yva = y_scaler.transform(y_val.reshape(-1,1)).astype(np.float32)\n",
    "yte = y_scaler.transform(y_test.reshape(-1,1)).astype(np.float32)\n",
    "\n",
    "def make_loaders(Xtr, ytr, Xva, yva, bs):\n",
    "    ds_tr = TensorDataset(torch.from_numpy(Xtr), torch.from_numpy(ytr))\n",
    "    ds_va = TensorDataset(torch.from_numpy(Xva), torch.from_numpy(yva))\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=bs, shuffle=True,  pin_memory=True)\n",
    "    dl_va = DataLoader(ds_va, batch_size=max(bs,2048), shuffle=False, pin_memory=True)\n",
    "    return dl_tr, dl_va\n",
    "\n",
    "train_loader, val_loader = make_loaders(Xtr, ytr, Xva, yva, batch_size)\n",
    "test_loader = DataLoader(TensorDataset(torch.from_numpy(Xte), torch.from_numpy(yte)),\n",
    "                         batch_size=max(batch_size,2048), shuffle=False, pin_memory=True)\n",
    "\n",
    "# ========= MODEL (mirror grid) =========\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_in, hidden, act=\"relu\", p=0.0):\n",
    "        super().__init__()\n",
    "        A = nn.ReLU if act==\"relu\" else nn.GELU\n",
    "        layers=[]; prev=d_in\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(prev,h), A(), nn.Dropout(p)]  # always include Dropout(p)\n",
    "            prev=h\n",
    "        layers += [nn.Linear(prev,1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "model = FFN(Xtr.shape[1], hidden, act=act_name, p=dropout_p).to(device)\n",
    "\n",
    "opt   = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
    "crit  = nn.MSELoss()\n",
    "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type==\"cuda\"))\n",
    "\n",
    "# ========= TRAIN (early stopping, same RMSE calc) =========\n",
    "best_rmse = float(\"inf\")\n",
    "best_state = None\n",
    "wait = 0\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    model.train()\n",
    "    for xb,yb in train_loader:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            pred = model(xb); loss = crit(pred,yb)\n",
    "        scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "\n",
    "    # val RMSE computed as mean of per-batch MSEs (grid style)\n",
    "    model.eval(); mse=0.0; n=0\n",
    "    with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "        for xb,yb in val_loader:\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb)\n",
    "            mse += ((pred-yb)**2).mean().item(); n += 1\n",
    "    mse /= max(1,n); rmse_val = float(np.sqrt(mse))\n",
    "    sched.step(mse)\n",
    "\n",
    "    print(f\"Epoch {ep:03d} | val RMSE (scaled): {rmse_val:.6f}\")\n",
    "\n",
    "    if rmse_val < best_rmse - 1e-6:\n",
    "        best_rmse = rmse_val\n",
    "        best_state = {k:v.detach().cpu() for k,v in model.state_dict().items()}\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Early stopping at epoch {ep}.\"); break\n",
    "\n",
    "print(f\"Training time: {time.perf_counter()-t0:.1f}s\")\n",
    "model.load_state_dict(best_state)\n",
    "torch.save(model.state_dict(), MODEL_PTH)\n",
    "\n",
    "# ========= TEST (invert scaling; metrics on original units) =========\n",
    "def eval_to_units(loader):\n",
    "    model.eval(); P=[]; T=[]\n",
    "    with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "        for xb,yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            P.append(model(xb).cpu().numpy())\n",
    "            T.append(yb.numpy())\n",
    "    P = np.vstack(P).ravel(); T = np.vstack(T).ravel()\n",
    "    P_u = y_scaler.inverse_transform(P.reshape(-1,1)).ravel()\n",
    "    T_u = y_scaler.inverse_transform(T.reshape(-1,1)).ravel()\n",
    "    rmse = np.sqrt(mean_squared_error(T_u, P_u))\n",
    "    mae  = mean_absolute_error(T_u, P_u)\n",
    "    r2   = r2_score(T_u, P_u)\n",
    "    return rmse, mae, r2, T_u, P_u\n",
    "\n",
    "# Train/Val/Test metrics in original units\n",
    "rmse_tr, mae_tr, r2_tr, _, _ = eval_to_units(train_loader)\n",
    "rmse_va, mae_va, r2_va, _, _ = eval_to_units(val_loader)\n",
    "rmse_te, mae_te, r2_te, y_true, y_pred = eval_to_units(test_loader)\n",
    "\n",
    "print(\"\\n=== Final Metrics (Descriptor NN; match-grid) ===\")\n",
    "print(f\"Train: RMSE={rmse_tr:.6f} | MAE={mae_tr:.6f} | R2={r2_tr:.6f}\")\n",
    "print(f\"Val:   RMSE={rmse_va:.6f} | MAE={mae_va:.6f} | R2={r2_va:.6f}\")\n",
    "print(f\"Test:  RMSE={rmse_te:.6f} | MAE={mae_te:.6f} | R2={r2_te:.6f}\")\n",
    "\n",
    "pd.DataFrame({\"y_true\": y_true, \"y_pred\": y_pred}).to_csv(PRED_CSV, index=False)\n",
    "print(f\"Saved test predictions â†’ {PRED_CSV}\")\n",
    "print(f\"Saved model â†’ {MODEL_PTH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml273a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
